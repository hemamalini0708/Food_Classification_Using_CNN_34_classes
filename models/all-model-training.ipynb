{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **VGG16 Using CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T02:45:01.299699Z",
     "iopub.status.busy": "2025-10-22T02:45:01.299429Z",
     "iopub.status.idle": "2025-10-22T05:06:52.296203Z",
     "shell.execute_reply": "2025-10-22T05:06:52.295285Z",
     "shell.execute_reply.started": "2025-10-22T02:45:01.299677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 02:45:02.948335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761101103.192788      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761101103.262320      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Starting VGG16 Model...\n",
      "STARTING VGG16 FOOD CLASSIFICATION\n",
      "============================================================\n",
      "Found 7956 images belonging to 34 classes.\n",
      "Found 1372 images belonging to 34 classes.\n",
      "Found 7956 training images\n",
      "Found 1372 validation images\n",
      "Building VGG16 with ImageNet weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761101122.191808      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1761101122.192567      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "VGG16 model built successfully with ImageNet weights!\n",
      "Phase 1: Training with frozen base layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761101129.615176     116 service.cc:148] XLA service 0x7f3768010850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761101129.616247     116 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1761101129.616283     116 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1761101130.106089     116 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/249\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:06:04\u001b[0m 16s/step - accuracy: 0.0625 - loss: 3.7005 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761101141.447932     116 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 954ms/step - accuracy: 0.0607 - loss: 3.4779 - precision: 0.2817 - recall: 3.6258e-04 - val_accuracy: 0.2981 - val_loss: 2.6570 - val_precision: 0.2222 - val_recall: 0.0015 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 651ms/step - accuracy: 0.2082 - loss: 2.7753 - precision: 0.6132 - recall: 0.0206 - val_accuracy: 0.4162 - val_loss: 2.0814 - val_precision: 0.7857 - val_recall: 0.1042 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 654ms/step - accuracy: 0.3103 - loss: 2.3918 - precision: 0.6946 - recall: 0.0816 - val_accuracy: 0.4483 - val_loss: 1.9395 - val_precision: 0.7525 - val_recall: 0.1640 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 645ms/step - accuracy: 0.3567 - loss: 2.2263 - precision: 0.6911 - recall: 0.1217 - val_accuracy: 0.4832 - val_loss: 1.7967 - val_precision: 0.7591 - val_recall: 0.2573 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 656ms/step - accuracy: 0.3910 - loss: 2.1075 - precision: 0.6895 - recall: 0.1642 - val_accuracy: 0.5044 - val_loss: 1.7084 - val_precision: 0.7953 - val_recall: 0.2690 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 654ms/step - accuracy: 0.4181 - loss: 2.0121 - precision: 0.7210 - recall: 0.1914 - val_accuracy: 0.5335 - val_loss: 1.6284 - val_precision: 0.7895 - val_recall: 0.2952 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 658ms/step - accuracy: 0.4498 - loss: 1.9102 - precision: 0.7319 - recall: 0.2207 - val_accuracy: 0.5394 - val_loss: 1.5610 - val_precision: 0.7899 - val_recall: 0.3426 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 649ms/step - accuracy: 0.4394 - loss: 1.9105 - precision: 0.7179 - recall: 0.2376 - val_accuracy: 0.5452 - val_loss: 1.5600 - val_precision: 0.7902 - val_recall: 0.3542 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 653ms/step - accuracy: 0.4689 - loss: 1.8368 - precision: 0.7306 - recall: 0.2616 - val_accuracy: 0.5678 - val_loss: 1.4939 - val_precision: 0.8019 - val_recall: 0.3659 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 649ms/step - accuracy: 0.4716 - loss: 1.7821 - precision: 0.7401 - recall: 0.2781 - val_accuracy: 0.5634 - val_loss: 1.5019 - val_precision: 0.7905 - val_recall: 0.3630 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 687ms/step - accuracy: 0.4974 - loss: 1.7770 - precision: 0.7536 - recall: 0.2821 - val_accuracy: 0.5722 - val_loss: 1.4746 - val_precision: 0.7958 - val_recall: 0.3834 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 678ms/step - accuracy: 0.4975 - loss: 1.7308 - precision: 0.7419 - recall: 0.2941 - val_accuracy: 0.5634 - val_loss: 1.4884 - val_precision: 0.7717 - val_recall: 0.3892 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 660ms/step - accuracy: 0.4904 - loss: 1.7758 - precision: 0.7309 - recall: 0.2859 - val_accuracy: 0.5831 - val_loss: 1.3856 - val_precision: 0.7823 - val_recall: 0.4373 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 671ms/step - accuracy: 0.5013 - loss: 1.6797 - precision: 0.7297 - recall: 0.3053 - val_accuracy: 0.5794 - val_loss: 1.3752 - val_precision: 0.7865 - val_recall: 0.4402 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 658ms/step - accuracy: 0.5140 - loss: 1.6525 - precision: 0.7555 - recall: 0.3344 - val_accuracy: 0.5940 - val_loss: 1.4167 - val_precision: 0.7766 - val_recall: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 662ms/step - accuracy: 0.5241 - loss: 1.6198 - precision: 0.7562 - recall: 0.3458 - val_accuracy: 0.6013 - val_loss: 1.3750 - val_precision: 0.7971 - val_recall: 0.4410 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 677ms/step - accuracy: 0.5212 - loss: 1.6295 - precision: 0.7585 - recall: 0.3398 - val_accuracy: 0.5955 - val_loss: 1.3749 - val_precision: 0.8134 - val_recall: 0.4162 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 684ms/step - accuracy: 0.5216 - loss: 1.6589 - precision: 0.7643 - recall: 0.3302 - val_accuracy: 0.6166 - val_loss: 1.3490 - val_precision: 0.8013 - val_recall: 0.4468 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 661ms/step - accuracy: 0.5231 - loss: 1.6485 - precision: 0.7491 - recall: 0.3360 - val_accuracy: 0.6217 - val_loss: 1.3088 - val_precision: 0.8185 - val_recall: 0.4570 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 660ms/step - accuracy: 0.5325 - loss: 1.6114 - precision: 0.7463 - recall: 0.3542 - val_accuracy: 0.5831 - val_loss: 1.4247 - val_precision: 0.7833 - val_recall: 0.4373 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 655ms/step - accuracy: 0.5325 - loss: 1.6046 - precision: 0.7579 - recall: 0.3453 - val_accuracy: 0.6057 - val_loss: 1.3644 - val_precision: 0.7820 - val_recall: 0.4628 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 661ms/step - accuracy: 0.5456 - loss: 1.5666 - precision: 0.7588 - recall: 0.3692 - val_accuracy: 0.5977 - val_loss: 1.3398 - val_precision: 0.7890 - val_recall: 0.4716 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 655ms/step - accuracy: 0.5453 - loss: 1.5414 - precision: 0.7581 - recall: 0.3672 - val_accuracy: 0.5999 - val_loss: 1.3582 - val_precision: 0.7856 - val_recall: 0.4701 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 659ms/step - accuracy: 0.5413 - loss: 1.5693 - precision: 0.7452 - recall: 0.3540 - val_accuracy: 0.6195 - val_loss: 1.2933 - val_precision: 0.8183 - val_recall: 0.4759 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 670ms/step - accuracy: 0.5415 - loss: 1.5275 - precision: 0.7618 - recall: 0.3716 - val_accuracy: 0.6122 - val_loss: 1.2909 - val_precision: 0.7941 - val_recall: 0.4723 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 660ms/step - accuracy: 0.5530 - loss: 1.5071 - precision: 0.7680 - recall: 0.3796 - val_accuracy: 0.6283 - val_loss: 1.2657 - val_precision: 0.8063 - val_recall: 0.4883 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 665ms/step - accuracy: 0.5520 - loss: 1.5351 - precision: 0.7571 - recall: 0.3675 - val_accuracy: 0.6173 - val_loss: 1.2691 - val_precision: 0.7986 - val_recall: 0.4883 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 661ms/step - accuracy: 0.5583 - loss: 1.5069 - precision: 0.7753 - recall: 0.3924 - val_accuracy: 0.6159 - val_loss: 1.3090 - val_precision: 0.8083 - val_recall: 0.4854 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 652ms/step - accuracy: 0.5565 - loss: 1.5011 - precision: 0.7724 - recall: 0.3901 - val_accuracy: 0.6217 - val_loss: 1.2803 - val_precision: 0.7952 - val_recall: 0.5036 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 657ms/step - accuracy: 0.5492 - loss: 1.4890 - precision: 0.7657 - recall: 0.3969 - val_accuracy: 0.6122 - val_loss: 1.3048 - val_precision: 0.8041 - val_recall: 0.4847 - learning_rate: 0.0010\n",
      "Phase 2: Fine-tuning with unfrozen layers...\n",
      "Epoch 31/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 689ms/step - accuracy: 0.5257 - loss: 1.6246 - precision: 0.7414 - recall: 0.3628 - val_accuracy: 0.6224 - val_loss: 1.2953 - val_precision: 0.7810 - val_recall: 0.4913 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 649ms/step - accuracy: 0.5899 - loss: 1.4078 - precision: 0.7779 - recall: 0.4363 - val_accuracy: 0.6538 - val_loss: 1.1997 - val_precision: 0.7996 - val_recall: 0.5408 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 657ms/step - accuracy: 0.6177 - loss: 1.2706 - precision: 0.7931 - recall: 0.4769 - val_accuracy: 0.6698 - val_loss: 1.1205 - val_precision: 0.8090 - val_recall: 0.5496 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 652ms/step - accuracy: 0.6233 - loss: 1.2564 - precision: 0.7985 - recall: 0.4890 - val_accuracy: 0.6808 - val_loss: 1.0991 - val_precision: 0.8130 - val_recall: 0.5641 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 656ms/step - accuracy: 0.6585 - loss: 1.1267 - precision: 0.8145 - recall: 0.5238 - val_accuracy: 0.6800 - val_loss: 1.0985 - val_precision: 0.8187 - val_recall: 0.5692 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 657ms/step - accuracy: 0.6744 - loss: 1.1043 - precision: 0.8306 - recall: 0.5367 - val_accuracy: 0.6669 - val_loss: 1.1420 - val_precision: 0.7963 - val_recall: 0.5671 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 656ms/step - accuracy: 0.6766 - loss: 1.0565 - precision: 0.8346 - recall: 0.5542 - val_accuracy: 0.6953 - val_loss: 1.0828 - val_precision: 0.8112 - val_recall: 0.6108 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 657ms/step - accuracy: 0.6993 - loss: 0.9994 - precision: 0.8387 - recall: 0.5776 - val_accuracy: 0.6844 - val_loss: 1.1010 - val_precision: 0.8020 - val_recall: 0.5962 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 655ms/step - accuracy: 0.6910 - loss: 1.0271 - precision: 0.8218 - recall: 0.5654 - val_accuracy: 0.6983 - val_loss: 1.0553 - val_precision: 0.8155 - val_recall: 0.6152 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 652ms/step - accuracy: 0.7016 - loss: 0.9597 - precision: 0.8393 - recall: 0.5958 - val_accuracy: 0.6953 - val_loss: 1.0560 - val_precision: 0.8194 - val_recall: 0.6086 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 656ms/step - accuracy: 0.7029 - loss: 0.9631 - precision: 0.8370 - recall: 0.5932 - val_accuracy: 0.6844 - val_loss: 1.1500 - val_precision: 0.7954 - val_recall: 0.6006 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 664ms/step - accuracy: 0.7294 - loss: 0.8913 - precision: 0.8529 - recall: 0.6192 - val_accuracy: 0.7099 - val_loss: 0.9976 - val_precision: 0.8161 - val_recall: 0.6370 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 752ms/step - accuracy: 0.7377 - loss: 0.8648 - precision: 0.8560 - recall: 0.6314 - val_accuracy: 0.7121 - val_loss: 1.0437 - val_precision: 0.8048 - val_recall: 0.6399 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 733ms/step - accuracy: 0.7425 - loss: 0.8361 - precision: 0.8556 - recall: 0.6401 - val_accuracy: 0.7092 - val_loss: 1.0196 - val_precision: 0.8208 - val_recall: 0.6341 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 728ms/step - accuracy: 0.7578 - loss: 0.8024 - precision: 0.8746 - recall: 0.6531 - val_accuracy: 0.6975 - val_loss: 1.0466 - val_precision: 0.8047 - val_recall: 0.6305 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 729ms/step - accuracy: 0.7546 - loss: 0.7936 - precision: 0.8627 - recall: 0.6565 - val_accuracy: 0.7092 - val_loss: 1.0504 - val_precision: 0.7977 - val_recall: 0.6523 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 739ms/step - accuracy: 0.7571 - loss: 0.7733 - precision: 0.8598 - recall: 0.6709 - val_accuracy: 0.7092 - val_loss: 1.0229 - val_precision: 0.8079 - val_recall: 0.6560 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 735ms/step - accuracy: 0.7710 - loss: 0.7429 - precision: 0.8715 - recall: 0.6797 - val_accuracy: 0.7332 - val_loss: 1.0194 - val_precision: 0.8206 - val_recall: 0.6633 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 728ms/step - accuracy: 0.7738 - loss: 0.7399 - precision: 0.8714 - recall: 0.6896 - val_accuracy: 0.7194 - val_loss: 1.0453 - val_precision: 0.7970 - val_recall: 0.6669 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 733ms/step - accuracy: 0.7837 - loss: 0.7033 - precision: 0.8769 - recall: 0.6982 - val_accuracy: 0.7267 - val_loss: 0.9979 - val_precision: 0.8214 - val_recall: 0.6538 - learning_rate: 1.0000e-04\n",
      "Training completed!\n",
      "Generating detailed validation report...\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 410ms/step\n",
      "Report saved to: /kaggle/working/VGG16_Model.txt\n",
      "\n",
      "FINAL RESULTS SUMMARY:\n",
      "   Accuracy:  0.7267 (72.67%)\n",
      "   Precision: 0.8214 (82.14%)\n",
      "   Recall:    0.6538 (65.38%)\n",
      "   Model saved: /kaggle/working/vgg16_food_model.h5\n",
      "   Report saved: /kaggle/working/VGG16_Model.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import datetime\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "class VGG16FoodClassifier:\n",
    "    def __init__(self):\n",
    "        self.data_dir = '/kaggle/input/food-classification-34-classes/food34_200_per_class'\n",
    "        self.img_size = (224, 224)\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 50\n",
    "        self.num_classes = 34\n",
    "        self.model_path = '/kaggle/working/vgg16_food_model.h5'\n",
    "        self.report_path = '/kaggle/working/VGG16_Model.txt'\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load and prepare data\"\"\"\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_dir = os.path.join(self.data_dir, 'train')\n",
    "        val_dir = os.path.join(self.data_dir, 'val')\n",
    "\n",
    "        train_gen = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        val_gen = val_datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        print(f\"Found {train_gen.samples} training images\")\n",
    "        print(f\"Found {val_gen.samples} validation images\")\n",
    "        return train_gen, val_gen, train_gen.class_indices\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build VGG16 model with ImageNet weights\"\"\"\n",
    "        print(\"Building VGG16 with ImageNet weights...\")\n",
    "        \n",
    "        # Load pre-trained VGG16\n",
    "        base_model = VGG16(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "\n",
    "        # Freeze base model initially\n",
    "        base_model.trainable = False\n",
    "\n",
    "        # Add custom classification head\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        predictions = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "        )\n",
    "        \n",
    "        print(\"VGG16 model built successfully with ImageNet weights!\")\n",
    "        return model\n",
    "\n",
    "    def train_model(self, train_generator, val_generator):\n",
    "        \"\"\"Train the model with two-phase approach\"\"\"\n",
    "        model = self.build_model()\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "            ModelCheckpoint(self.model_path, monitor='val_accuracy', save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-7)\n",
    "        ]\n",
    "\n",
    "        print(\"Phase 1: Training with frozen base layers...\")\n",
    "        history1 = model.fit(\n",
    "            train_generator,\n",
    "            epochs=30,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        print(\"Phase 2: Fine-tuning with unfrozen layers...\")\n",
    "        # Unfreeze some layers for fine-tuning\n",
    "        for layer in model.layers[-8:]:\n",
    "            if not isinstance(layer, BatchNormalization):\n",
    "                layer.trainable = True\n",
    "\n",
    "        # Recompile with lower learning rate\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "        history2 = model.fit(\n",
    "            train_generator,\n",
    "            epochs=self.epochs,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            initial_epoch=30\n",
    "        )\n",
    "        \n",
    "        return model, history2\n",
    "\n",
    "    def calculate_detailed_metrics(self, y_true, y_pred, num_classes):\n",
    "        \"\"\"Calculate TP, TN, FP, FN for each class\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        TP = np.diag(cm)\n",
    "        FP = np.sum(cm, axis=0) - TP\n",
    "        FN = np.sum(cm, axis=1) - TP\n",
    "        TN = np.sum(cm) - (FP + FN + TP)\n",
    "        \n",
    "        return TP, TN, FP, FN, cm\n",
    "\n",
    "    def generate_report(self, model, val_generator, class_indices):\n",
    "        \"\"\"Generate comprehensive validation report with all metrics\"\"\"\n",
    "        print(\"Generating detailed validation report...\")\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = model.predict(val_generator)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = val_generator.classes\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "        \n",
    "        # Calculate TP, TN, FP, FN\n",
    "        TP, TN, FP, FN, cm = self.calculate_detailed_metrics(y_true, y_pred_classes, self.num_classes)\n",
    "        \n",
    "        # Generate report content\n",
    "        report_content = f\"\"\"\n",
    "VGG16 MODEL - COMPREHENSIVE VALIDATION REPORT\n",
    "============================================================\n",
    "Generated: {datetime.datetime.now()}\n",
    "\n",
    "DATASET INFORMATION:\n",
    "- Training samples: {val_generator.samples}\n",
    "- Number of classes: {self.num_classes}\n",
    "- Class names: {list(class_indices.keys())}\n",
    "\n",
    "OVERALL METRICS:\n",
    "----------------------------------------\n",
    "Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\n",
    "Precision: {precision:.4f} ({precision*100:.2f}%)\n",
    "Recall:    {recall:.4f} ({recall*100:.2f}%)\n",
    "F1-Score:  {f1:.4f} ({f1*100:.2f}%)\n",
    "\n",
    "CONFUSION MATRIX SUMMARY:\n",
    "----------------------------------------\n",
    "Total True Positives (TP):  {int(np.sum(TP))}\n",
    "Total True Negatives (TN):  {int(np.sum(TN))}\n",
    "Total False Positives (FP): {int(np.sum(FP))}\n",
    "Total False Negatives (FN): {int(np.sum(FN))}\n",
    "\n",
    "DETAILED PER-CLASS METRICS:\n",
    "----------------------------------------\n",
    "{'Class':<20} {'TP':<8} {'TN':<8} {'FP':<8} {'FN':<8} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\n",
    "{'-'*90}\n",
    "\"\"\"\n",
    "        # Add per-class metrics\n",
    "        class_names = list(class_indices.keys())\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            class_precision = TP[i] / (TP[i] + FP[i]) if (TP[i] + FP[i]) > 0 else 0\n",
    "            class_recall = TP[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0\n",
    "            class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "            \n",
    "            report_content += f\"{class_name:<20} {int(TP[i]):<8} {int(TN[i]):<8} {int(FP[i]):<8} {int(FN[i]):<8} {class_precision:.4f}     {class_recall:.4f}      {class_f1:.4f}\\n\"\n",
    "\n",
    "        # Performance assessment\n",
    "        report_content += f\"\"\"\n",
    "PERFORMANCE ASSESSMENT:\n",
    "----------------------------------------\n",
    "\"\"\"\n",
    "        if accuracy >= 0.90:\n",
    "            report_content += \"90%+ Accuracy Achieved!\"\n",
    "        elif accuracy >= 0.80:\n",
    "            report_content += \"80%+ Accuracy!\"\n",
    "        elif accuracy >= 0.70:\n",
    "            report_content += \"70%+ Accuracy!\"\n",
    "        elif accuracy >= 0.60:\n",
    "            report_content += \"Needs Improvement\"\n",
    "        else:\n",
    "            report_content += \"Model needs significant improvement\"\n",
    "\n",
    "        report_content += f\"\"\"\n",
    "\n",
    "MODEL TRAINING INFORMATION:\n",
    "----------------------------------------\n",
    "- Pre-trained model: VGG16 with ImageNet weights\n",
    "- Total epochs: {self.epochs}\n",
    "- Batch size: {self.batch_size}\n",
    "- Image size: {self.img_size}\n",
    "- Number of classes: {self.num_classes}\n",
    "- Model saved: {self.model_path}\n",
    "\"\"\"\n",
    "\n",
    "        # Save report\n",
    "        with open(self.report_path, 'w') as f:\n",
    "            f.write(report_content)\n",
    "\n",
    "        print(f\"Report saved to: {self.report_path}\")\n",
    "        return report_content\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main execution function\"\"\"\n",
    "        print(\"STARTING VGG16 FOOD CLASSIFICATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load data\n",
    "        train_gen, val_gen, class_indices = self.load_data()\n",
    "        \n",
    "        # Train model\n",
    "        model, history = self.train_model(train_gen, val_gen)\n",
    "        print(\"Training completed!\")\n",
    "        \n",
    "        # Generate report\n",
    "        report_content = self.generate_report(model, val_gen, class_indices)\n",
    "        \n",
    "        # Final results summary\n",
    "        print(f\"\\nFINAL RESULTS SUMMARY:\")\n",
    "        print(f\"   Accuracy:  {history.history['val_accuracy'][-1]:.4f} ({history.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "        print(f\"   Precision: {history.history['val_precision'][-1]:.4f} ({history.history['val_precision'][-1]*100:.2f}%)\")\n",
    "        print(f\"   Recall:    {history.history['val_recall'][-1]:.4f} ({history.history['val_recall'][-1]*100:.2f}%)\")\n",
    "        print(f\"   Model saved: {self.model_path}\")\n",
    "        print(f\"   Report saved: {self.report_path}\")\n",
    "        \n",
    "        return model, report_content\n",
    "\n",
    "# Run VGG16 Model\n",
    "print(\"Starting VGG16 Model...\")\n",
    "vgg16_classifier = VGG16FoodClassifier()\n",
    "vgg16_model, vgg16_report = vgg16_classifier.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custom Model Usinng CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and configure for maximum performance\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Configure GPU for better performance\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✓ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# **Configuration Class**\n",
    "class CustomModelConfig:\n",
    "    \"\"\"Configuration class for Custom CNN model parameters and paths\"\"\"\n",
    "    def __init__(self):\n",
    "        # Use appropriate path for your environment\n",
    "        self.DATA_DIR = '/kaggle/input/food-classification-34-classes/food34_200_per_class'  # For Kaggle\n",
    "        \n",
    "        self.IMG_SIZE = (224, 224)\n",
    "        self.BATCH_SIZE = 32\n",
    "        self.EPOCHS = 50  \n",
    "        self.NUM_CLASSES = 34\n",
    "        \n",
    "        # Save paths\n",
    "        self.CUSTOM_MODEL_PATH = '/kaggle/working/custom_cnn_food_model.h5'\n",
    "        self.REPORT_PATH = '/kaggle/working/Custom_CNN_Model_Report.txt'\n",
    "        self.LOG_PATH = '/kaggle/working/custom_cnn_training.log'\n",
    "\n",
    "        # Data augmentation parameters (more aggressive for custom model)\n",
    "        self.ROTATION_RANGE = 25\n",
    "        self.WIDTH_SHIFT_RANGE = 0.15\n",
    "        self.HEIGHT_SHIFT_RANGE = 0.15\n",
    "        self.SHEAR_RANGE = 0.15\n",
    "        self.ZOOM_RANGE = 0.15\n",
    "        self.HORIZONTAL_FLIP = True\n",
    "        self.VERTICAL_FLIP = True\n",
    "        self.BRIGHTNESS_RANGE = [0.8, 1.2]\n",
    "        self.VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# **Setup Logging Function**\n",
    "def setup_logging_custom(config):\n",
    "    \"\"\"Setup logging for Custom CNN\"\"\"\n",
    "    try:\n",
    "        # Create logger\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        # Clear any existing handlers\n",
    "        for handler in logger.handlers[:]:\n",
    "            logger.removeHandler(handler)\n",
    "\n",
    "        # Create formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "        # File handler\n",
    "        file_handler = logging.FileHandler(config.LOG_PATH, mode='w')\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        # Stream handler (console)\n",
    "        stream_handler = logging.StreamHandler(sys.stdout)\n",
    "        stream_handler.setLevel(logging.INFO)\n",
    "        stream_handler.setFormatter(formatter)\n",
    "\n",
    "        # Add handlers to logger\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "        logging.info(\"Custom CNN Logging setup successfully for Kaggle!\")\n",
    "        logging.info(f\"Log file: {config.LOG_PATH}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Custom CNN Logging setup failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# **Data Generator Class**\n",
    "class CustomDataGenerator:\n",
    "    \"\"\"Handles data loading and augmentation for Custom CNN\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.train_generator = None\n",
    "        self.validation_generator = None\n",
    "        self.class_indices = None\n",
    "        logging.info(\"CustomDataGenerator initialized for Kaggle\")\n",
    "\n",
    "    def create_data_generators(self):\n",
    "        \"\"\"Create data generators with augmentation\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Creating Custom CNN data generators with augmentation...\")\n",
    "\n",
    "            # Training generator with more aggressive augmentation for custom model\n",
    "            train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=self.config.ROTATION_RANGE,\n",
    "                width_shift_range=self.config.WIDTH_SHIFT_RANGE,\n",
    "                height_shift_range=self.config.HEIGHT_SHIFT_RANGE,\n",
    "                shear_range=self.config.SHEAR_RANGE,\n",
    "                zoom_range=self.config.ZOOM_RANGE,\n",
    "                horizontal_flip=self.config.HORIZONTAL_FLIP,\n",
    "                vertical_flip=self.config.VERTICAL_FLIP,\n",
    "                brightness_range=self.config.BRIGHTNESS_RANGE,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "\n",
    "            # Validation generator (only rescaling)\n",
    "            val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "            # Create generators\n",
    "            train_dir = os.path.join(self.config.DATA_DIR, 'train')\n",
    "            val_dir = os.path.join(self.config.DATA_DIR, 'val')\n",
    "\n",
    "            self.train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,\n",
    "                target_size=self.config.IMG_SIZE,\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True,\n",
    "                seed=42\n",
    "            )\n",
    "\n",
    "            self.validation_generator = val_datagen.flow_from_directory(\n",
    "                val_dir,\n",
    "                target_size=self.config.IMG_SIZE,\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                shuffle=False,\n",
    "                seed=42\n",
    "            )\n",
    "\n",
    "            self.class_indices = self.train_generator.class_indices\n",
    "            logging.info(f\"Custom CNN - Found {len(self.class_indices)} classes\")\n",
    "            logging.info(f\"Custom CNN - Training samples: {self.train_generator.samples}\")\n",
    "            logging.info(f\"Custom CNN - Validation samples: {self.validation_generator.samples}\")\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating Custom CNN data generators: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# **Custom CNN Model Class**\n",
    "class CustomFoodModel:\n",
    "    \"\"\"Builds and manages the custom CNN model from scratch\"\"\"\n",
    "\n",
    "    def __init__(self, config, num_classes):\n",
    "        self.config = config\n",
    "        self.num_classes = num_classes\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        logging.info(\"CustomFoodModel initialized for Kaggle\")\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build custom CNN model from scratch with optimized architecture\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Building Custom CNN model from scratch...\")\n",
    "\n",
    "            self.model = Sequential([\n",
    "                # First Conv Block\n",
    "                Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                       input_shape=(*self.config.IMG_SIZE, 3)),\n",
    "                BatchNormalization(),\n",
    "                Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling2D(2, 2),\n",
    "                Dropout(0.25),\n",
    "\n",
    "                # Second Conv Block\n",
    "                Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling2D(2, 2),\n",
    "                Dropout(0.25),\n",
    "\n",
    "                # Third Conv Block\n",
    "                Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling2D(2, 2),\n",
    "                Dropout(0.25),\n",
    "\n",
    "                # Fourth Conv Block\n",
    "                Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling2D(2, 2),\n",
    "                Dropout(0.25),\n",
    "\n",
    "                # Fifth Conv Block\n",
    "                Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "                BatchNormalization(),\n",
    "                MaxPooling2D(2, 2),\n",
    "                Dropout(0.3),\n",
    "\n",
    "                # Classifier Head\n",
    "                Flatten(),\n",
    "                Dense(1024, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.5),\n",
    "                Dense(512, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.4),\n",
    "                Dense(256, activation='relu'),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.3),\n",
    "                Dense(self.num_classes, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            logging.info(\"Custom CNN model built successfully!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error building Custom CNN model: {str(e)}\")\n",
    "            # Fallback: Simpler model if memory issues\n",
    "            logging.info(\"Creating simpler fallback model...\")\n",
    "            self._create_simpler_model()\n",
    "            return True\n",
    "\n",
    "    def _create_simpler_model(self):\n",
    "        \"\"\"Create a simpler CNN model as fallback\"\"\"\n",
    "        self.model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(*self.config.IMG_SIZE, 3)),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        logging.info(\"Simpler fallback model created successfully!\")\n",
    "\n",
    "    def compile_model(self):\n",
    "        \"\"\"Compile the Custom CNN model with appropriate settings\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Compiling Custom CNN model...\")\n",
    "\n",
    "            self.model.compile(\n",
    "                optimizer=Adam(learning_rate=0.001),  # Higher learning rate for custom model\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[\n",
    "                    'accuracy',\n",
    "                    Precision(name='precision'),\n",
    "                    Recall(name='recall')\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            logging.info(\"Custom CNN model compiled successfully!\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error compiling Custom CNN model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_callbacks(self):\n",
    "        \"\"\"Define training callbacks optimized for custom model\"\"\"\n",
    "        try:\n",
    "            callbacks = [\n",
    "                EarlyStopping(\n",
    "                    monitor='val_accuracy',\n",
    "                    patience=12,  # More patience for custom model\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=1\n",
    "                ),\n",
    "                ModelCheckpoint(\n",
    "                    self.config.CUSTOM_MODEL_PATH,\n",
    "                    monitor='val_accuracy',\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=False,\n",
    "                    verbose=1\n",
    "                ),\n",
    "                ReduceLROnPlateau(\n",
    "                    monitor='val_loss',\n",
    "                    factor=0.5,  # Less aggressive reduction\n",
    "                    patience=6,\n",
    "                    min_lr=1e-6,\n",
    "                    verbose=1\n",
    "                )\n",
    "            ]\n",
    "            logging.info(\"Custom CNN callbacks defined successfully!\")\n",
    "            return callbacks\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating Custom CNN callbacks: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def display_summary(self):\n",
    "        \"\"\"Display model summary\"\"\"\n",
    "        try:\n",
    "            self.model.summary()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error displaying Custom CNN model summary: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# **Training Class**\n",
    "class CustomModelTrainer:\n",
    "    \"\"\"Handles Custom CNN model training and evaluation\"\"\"\n",
    "\n",
    "    def __init__(self, config, model, data_generator):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.data_generator = data_generator\n",
    "        self.history = None\n",
    "        logging.info(\"CustomModelTrainer initialized\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Train the Custom CNN model\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting Custom CNN model training...\")\n",
    "\n",
    "            callbacks = self.model.get_callbacks()\n",
    "\n",
    "            self.history = self.model.model.fit(\n",
    "                self.data_generator.train_generator,\n",
    "                epochs=self.config.EPOCHS,\n",
    "                validation_data=self.data_generator.validation_generator,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            logging.info(\"Custom CNN model training completed successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during Custom CNN training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive validation report\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Generating Custom CNN validation report...\")\n",
    "\n",
    "            # Get predictions\n",
    "            validation_generator = self.data_generator.validation_generator\n",
    "            y_pred = self.model.model.predict(validation_generator)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            y_true = validation_generator.classes\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                y_true, y_pred_classes, average='weighted'\n",
    "            )\n",
    "\n",
    "            # Confusion matrix\n",
    "            cm = confusion_matrix(y_true, y_pred_classes)\n",
    "            FP = cm.sum(axis=0) - np.diag(cm)\n",
    "            FN = cm.sum(axis=1) - np.diag(cm)\n",
    "            TP = np.diag(cm)\n",
    "            TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "            # Save report\n",
    "            report_content = self._create_report_content(\n",
    "                accuracy, precision, recall, f1, TP, TN, FP, FN, cm\n",
    "            )\n",
    "\n",
    "            with open(self.config.REPORT_PATH, 'w') as f:\n",
    "                f.write(report_content)\n",
    "\n",
    "            logging.info(f\"Custom CNN validation report saved to: {self.config.REPORT_PATH}\")\n",
    "            \n",
    "            # Also save JSON report\n",
    "            self._save_json_report(accuracy, precision, recall, f1, TP, TN, FP, FN)\n",
    "            \n",
    "            return report_content\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating Custom CNN validation report: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _create_report_content(self, accuracy, precision, recall, f1, TP, TN, FP, FN, cm):\n",
    "        \"\"\"Create formatted report content\"\"\"\n",
    "        report = []\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(\"CUSTOM CNN MODEL - VALIDATION REPORT\")\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(f\"Generated on: {datetime.datetime.now()}\")\n",
    "        report.append(f\"Model: Custom CNN (Built from Scratch)\")\n",
    "        report.append(f\"Dataset: Food34 (200 per class)\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Overall metrics\n",
    "        report.append(\"OVERALL METRICS:\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        report.append(f\"Precision: {precision:.4f}\")\n",
    "        report.append(f\"Recall:    {recall:.4f}\")\n",
    "        report.append(f\"F1-Score:  {f1:.4f}\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Per-class metrics\n",
    "        report.append(\"PER-CLASS METRICS:\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"{'Class':<20} {'TP':<6} {'TN':<6} {'FP':<6} {'FN':<6}\")\n",
    "        report.append(\"-\" * 60)\n",
    "\n",
    "        class_names = list(self.data_generator.class_indices.keys())\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            report.append(f\"{class_name:<20} {TP[i]:<6} {TN[i]:<6} {FP[i]:<6} {FN[i]:<6}\")\n",
    "\n",
    "        report.append(\"\")\n",
    "        report.append(\"CONFUSION MATRIX:\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(str(cm))\n",
    "\n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "    def _save_json_report(self, accuracy, precision, recall, f1, TP, TN, FP, FN):\n",
    "        \"\"\"Save JSON report\"\"\"\n",
    "        json_report_path = self.config.REPORT_PATH.replace('.txt', '.json')\n",
    "        metrics = {\n",
    "            \"generated_on\": str(datetime.datetime.now()),\n",
    "            \"model\": \"Custom_CNN\",\n",
    "            \"accuracy\": float(accuracy),\n",
    "            \"precision\": float(precision),\n",
    "            \"recall\": float(recall),\n",
    "            \"f1_score\": float(f1),\n",
    "            \"TP\": TP.tolist(),\n",
    "            \"TN\": TN.tolist(),\n",
    "            \"FP\": FP.tolist(),\n",
    "            \"FN\": FN.tolist(),\n",
    "            \"class_indices\": self.data_generator.class_indices\n",
    "        }\n",
    "        \n",
    "        with open(json_report_path, 'w') as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "        logging.info(f\"Custom CNN JSON report saved to: {json_report_path}\")\n",
    "\n",
    "# **Main Pipeline Class**\n",
    "class CustomFoodClassificationPipeline:\n",
    "    def __init__(self):\n",
    "        self.config = CustomModelConfig()\n",
    "        self.data_generator = None\n",
    "        self.model = None\n",
    "        self.trainer = None\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Execute the complete training pipeline\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting Custom CNN Food Classification Pipeline on Kaggle...\")\n",
    "\n",
    "            # Step 1: Create data generators\n",
    "            self.data_generator = CustomDataGenerator(self.config)\n",
    "            self.data_generator.create_data_generators()\n",
    "\n",
    "            # Step 2: Build and compile model\n",
    "            self.model = CustomFoodModel(self.config, self.config.NUM_CLASSES)\n",
    "            self.model.build_model()\n",
    "            self.model.compile_model()\n",
    "\n",
    "            # Display model summary\n",
    "            logging.info(\"Custom CNN Model Summary:\")\n",
    "            self.model.display_summary()\n",
    "\n",
    "            # Step 3: Train model\n",
    "            self.trainer = CustomModelTrainer(self.config, self.model, self.data_generator)\n",
    "            self.trainer.train_model()\n",
    "\n",
    "            # Step 4: Generate report\n",
    "            report = self.trainer.generate_report()\n",
    "\n",
    "            # Final success message\n",
    "            logging.info(\"Custom CNN Pipeline completed successfully!\")\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"CUSTOM CNN TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Model saved: {self.config.CUSTOM_MODEL_PATH}\")\n",
    "            print(f\"Report saved: {self.config.REPORT_PATH}\")\n",
    "            print(f\"Log file: {self.config.LOG_PATH}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Custom CNN Pipeline failed on Kaggle: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# **Execute the pipeline**\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Initialize config first\n",
    "        config = CustomModelConfig()\n",
    "        \n",
    "        # Setup logging\n",
    "        if setup_logging_custom(config):\n",
    "            pipeline = CustomFoodClassificationPipeline()\n",
    "            pipeline.run_pipeline()\n",
    "        else:\n",
    "            print(\"Failed to setup Custom CNN logging.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Custom CNN main execution failed on Kaggle: {str(e)}\")\n",
    "\n",
    "# **Standalone Evaluation Code**\n",
    "def evaluate_custom_model():\n",
    "    \"\"\"Standalone function to evaluate the trained Custom CNN model\"\"\"\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"CUSTOM CNN MODEL EVALUATION - KAGGLE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        config = CustomModelConfig()\n",
    "        \n",
    "        # Load the trained model\n",
    "        if os.path.exists(config.CUSTOM_MODEL_PATH):\n",
    "            model = load_model(config.CUSTOM_MODEL_PATH)\n",
    "            print(\"✓ Custom CNN model loaded successfully\")\n",
    "            \n",
    "            # Create validation generator\n",
    "            val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "            val_dir = os.path.join(config.DATA_DIR, 'val')\n",
    "            \n",
    "            val_generator = val_datagen.flow_from_directory(\n",
    "                val_dir,\n",
    "                target_size=config.IMG_SIZE,\n",
    "                batch_size=config.BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "            # Predict\n",
    "            y_pred = model.predict(val_generator)\n",
    "            y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            y_true = val_generator.classes\n",
    "\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "            \n",
    "            print(f\"✓ Custom CNN Evaluation Results:\")\n",
    "            print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "            print(f\"  Precision: {precision:.4f}\")\n",
    "            print(f\"  Recall:    {recall:.4f}\")\n",
    "            print(f\"  F1-Score:  {f1:.4f}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"✗ Custom CNN model file not found in Kaggle working directory\")\n",
    "            return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Custom CNN evaluation failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run evaluation after training\n",
    "print(\"\\nStarting Custom CNN evaluation on Kaggle...\")\n",
    "evaluate_custom_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ResNet Model Using CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T05:12:00.792880Z",
     "iopub.status.busy": "2025-10-22T05:12:00.792019Z",
     "iopub.status.idle": "2025-10-22T07:19:28.187956Z",
     "shell.execute_reply": "2025-10-22T07:19:28.187028Z",
     "shell.execute_reply.started": "2025-10-22T05:12:00.792849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "Starting ResNet Model...\n",
      "STARTING RESNET50 FOOD CLASSIFICATION\n",
      "============================================================\n",
      "Found 7956 images belonging to 34 classes.\n",
      "Found 1372 images belonging to 34 classes.\n",
      "Found 7956 training images\n",
      "Found 1372 validation images\n",
      "Building ResNet50 with ImageNet weights...\n",
      "ResNet50 model built successfully with ImageNet weights!\n",
      "Phase 1: Training with frozen base layers...\n",
      "Epoch 1/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 783ms/step - accuracy: 0.0301 - loss: 3.6383 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0561 - val_loss: 3.4761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 736ms/step - accuracy: 0.0465 - loss: 3.4879 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0576 - val_loss: 3.4380 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 721ms/step - accuracy: 0.0441 - loss: 3.4719 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0532 - val_loss: 3.4198 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 723ms/step - accuracy: 0.0439 - loss: 3.4596 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0627 - val_loss: 3.3977 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 730ms/step - accuracy: 0.0448 - loss: 3.4666 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0620 - val_loss: 3.3979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 723ms/step - accuracy: 0.0562 - loss: 3.4479 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0627 - val_loss: 3.3921 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 722ms/step - accuracy: 0.0540 - loss: 3.4407 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0590 - val_loss: 3.3915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 728ms/step - accuracy: 0.0515 - loss: 3.4458 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0656 - val_loss: 3.3822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 716ms/step - accuracy: 0.0527 - loss: 3.4265 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0423 - val_loss: 3.3935 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 718ms/step - accuracy: 0.0505 - loss: 3.4291 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0612 - val_loss: 3.3753 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 722ms/step - accuracy: 0.0551 - loss: 3.4189 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0576 - val_loss: 3.3733 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 728ms/step - accuracy: 0.0609 - loss: 3.4085 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0889 - val_loss: 3.3447 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 729ms/step - accuracy: 0.0539 - loss: 3.4056 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0656 - val_loss: 3.3828 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 734ms/step - accuracy: 0.0531 - loss: 3.4201 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0751 - val_loss: 3.3880 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 728ms/step - accuracy: 0.0503 - loss: 3.4235 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0729 - val_loss: 3.3653 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 724ms/step - accuracy: 0.0573 - loss: 3.4109 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0787 - val_loss: 3.3471 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 721ms/step - accuracy: 0.0565 - loss: 3.4065 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0787 - val_loss: 3.3479 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 726ms/step - accuracy: 0.0625 - loss: 3.4033 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0692 - val_loss: 3.3420 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 724ms/step - accuracy: 0.0565 - loss: 3.4050 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0794 - val_loss: 3.3449 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 20/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 722ms/step - accuracy: 0.0571 - loss: 3.3904 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0889 - val_loss: 3.3255 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 21/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 720ms/step - accuracy: 0.0592 - loss: 3.3885 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0700 - val_loss: 3.3545 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 22/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 723ms/step - accuracy: 0.0569 - loss: 3.4063 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0969 - val_loss: 3.3132 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 23/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 719ms/step - accuracy: 0.0565 - loss: 3.3829 - precision: 0.4520 - recall: 2.9084e-04 - val_accuracy: 0.0787 - val_loss: 3.3247 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 24/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 718ms/step - accuracy: 0.0633 - loss: 3.3774 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0773 - val_loss: 3.3101 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 25/25\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 718ms/step - accuracy: 0.0618 - loss: 3.3965 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0641 - val_loss: 3.3216 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Phase 2: Fine-tuning with unfrozen layers...\n",
      "Epoch 26/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 769ms/step - accuracy: 0.0451 - loss: 3.5316 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0649 - val_loss: 3.3874 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 725ms/step - accuracy: 0.0582 - loss: 3.4042 - precision: 0.7680 - recall: 1.8187e-04 - val_accuracy: 0.0977 - val_loss: 3.3414 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 719ms/step - accuracy: 0.0670 - loss: 3.3842 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0831 - val_loss: 3.3178 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 720ms/step - accuracy: 0.0640 - loss: 3.3645 - precision: 0.2180 - recall: 7.1541e-05 - val_accuracy: 0.0612 - val_loss: 3.3503 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 723ms/step - accuracy: 0.0699 - loss: 3.3556 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0802 - val_loss: 3.2949 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 715ms/step - accuracy: 0.0759 - loss: 3.3496 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0773 - val_loss: 3.3084 - val_precision: 0.6667 - val_recall: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 718ms/step - accuracy: 0.0764 - loss: 3.3454 - precision: 0.2530 - recall: 1.1557e-04 - val_accuracy: 0.0816 - val_loss: 3.2639 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 725ms/step - accuracy: 0.0772 - loss: 3.3275 - precision: 0.7448 - recall: 4.1606e-04 - val_accuracy: 0.0692 - val_loss: 3.2982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 721ms/step - accuracy: 0.0866 - loss: 3.2921 - precision: 0.4712 - recall: 7.1436e-04 - val_accuracy: 0.0773 - val_loss: 3.2526 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 717ms/step - accuracy: 0.0788 - loss: 3.3167 - precision: 0.4893 - recall: 3.1416e-04 - val_accuracy: 0.0773 - val_loss: 3.2356 - val_precision: 0.5000 - val_recall: 7.2886e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 722ms/step - accuracy: 0.0820 - loss: 3.3059 - precision: 0.6887 - recall: 5.6546e-04 - val_accuracy: 0.0897 - val_loss: 3.2312 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 716ms/step - accuracy: 0.0811 - loss: 3.2983 - precision: 0.8010 - recall: 5.1227e-04 - val_accuracy: 0.0875 - val_loss: 3.2585 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 718ms/step - accuracy: 0.0756 - loss: 3.2791 - precision: 0.5208 - recall: 7.4066e-04 - val_accuracy: 0.0875 - val_loss: 3.2065 - val_precision: 0.5000 - val_recall: 7.2886e-04 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 719ms/step - accuracy: 0.0857 - loss: 3.2705 - precision: 0.3802 - recall: 6.5615e-04 - val_accuracy: 0.0969 - val_loss: 3.2212 - val_precision: 0.6250 - val_recall: 0.0036 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 719ms/step - accuracy: 0.0890 - loss: 3.2573 - precision: 0.3219 - recall: 0.0010 - val_accuracy: 0.0845 - val_loss: 3.2194 - val_precision: 0.8000 - val_recall: 0.0029 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 720ms/step - accuracy: 0.0874 - loss: 3.2721 - precision: 0.7336 - recall: 0.0030 - val_accuracy: 0.0897 - val_loss: 3.1839 - val_precision: 0.6667 - val_recall: 0.0015 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 716ms/step - accuracy: 0.0945 - loss: 3.2551 - precision: 0.6422 - recall: 0.0015 - val_accuracy: 0.0692 - val_loss: 3.3008 - val_precision: 0.2353 - val_recall: 0.0058 - learning_rate: 1.0000e-04\n",
      "Training completed!\n",
      "Generating detailed validation report...\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 482ms/step\n",
      "Report saved to: /kaggle/working/ResNet_Model.txt\n",
      "\n",
      "📊 FINAL RESULTS SUMMARY:\n",
      "   Accuracy:  0.0692 (6.92%)\n",
      "   Precision: 0.2353 (23.53%)\n",
      "   Recall:    0.0058 (0.58%)\n",
      "   Model saved: /kaggle/working/resnet_food_model.h5\n",
      "   Report saved: /kaggle/working/ResNet_Model.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import datetime\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "class ResNetFoodClassifier:\n",
    "    def __init__(self):\n",
    "        self.data_dir = '/kaggle/input/food-classification-34-classes/food34_200_per_class'\n",
    "        self.img_size = (224, 224)\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 50\n",
    "        self.num_classes = 34\n",
    "        self.model_path = '/kaggle/working/resnet_food_model.h5'\n",
    "        self.report_path = '/kaggle/working/ResNet_Model.txt'\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load and prepare data\"\"\"\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_dir = os.path.join(self.data_dir, 'train')\n",
    "        val_dir = os.path.join(self.data_dir, 'val')\n",
    "\n",
    "        train_gen = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        val_gen = val_datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=self.img_size,\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        print(f\"Found {train_gen.samples} training images\")\n",
    "        print(f\"Found {val_gen.samples} validation images\")\n",
    "        return train_gen, val_gen, train_gen.class_indices\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build ResNet50 model with ImageNet weights\"\"\"\n",
    "        print(\"Building ResNet50 with ImageNet weights...\")\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        base_model = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(224, 224, 3)\n",
    "        )\n",
    "\n",
    "        # Freeze base model initially\n",
    "        base_model.trainable = False\n",
    "\n",
    "        # Add custom classification head\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        predictions = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "        )\n",
    "        \n",
    "        print(\"ResNet50 model built successfully with ImageNet weights!\")\n",
    "        return model\n",
    "\n",
    "    def train_model(self, train_generator, val_generator):\n",
    "        \"\"\"Train the model with two-phase approach\"\"\"\n",
    "        model = self.build_model()\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "            ModelCheckpoint(self.model_path, monitor='val_accuracy', save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-7)\n",
    "        ]\n",
    "\n",
    "        print(\"Phase 1: Training with frozen base layers...\")\n",
    "        history1 = model.fit(\n",
    "            train_generator,\n",
    "            epochs=25,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        print(\"Phase 2: Fine-tuning with unfrozen layers...\")\n",
    "        # Unfreeze last layers for fine-tuning\n",
    "        for layer in model.layers[-20:]:\n",
    "            if not isinstance(layer, BatchNormalization):\n",
    "                layer.trainable = True\n",
    "\n",
    "        # Recompile with lower learning rate\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    "        )\n",
    "\n",
    "        history2 = model.fit(\n",
    "            train_generator,\n",
    "            epochs=self.epochs,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,\n",
    "            initial_epoch=25\n",
    "        )\n",
    "        \n",
    "        return model, history2\n",
    "\n",
    "    def calculate_detailed_metrics(self, y_true, y_pred, num_classes):\n",
    "        \"\"\"Calculate TP, TN, FP, FN for each class\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        TP = np.diag(cm)\n",
    "        FP = np.sum(cm, axis=0) - TP\n",
    "        FN = np.sum(cm, axis=1) - TP\n",
    "        TN = np.sum(cm) - (FP + FN + TP)\n",
    "        \n",
    "        return TP, TN, FP, FN, cm\n",
    "\n",
    "    def generate_report(self, model, val_generator, class_indices):\n",
    "        \"\"\"Generate comprehensive validation report with all metrics\"\"\"\n",
    "        print(\"Generating detailed validation report...\")\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = model.predict(val_generator)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = val_generator.classes\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "        \n",
    "        # Calculate TP, TN, FP, FN\n",
    "        TP, TN, FP, FN, cm = self.calculate_detailed_metrics(y_true, y_pred_classes, self.num_classes)\n",
    "        \n",
    "        # Generate report content\n",
    "        report_content = f\"\"\"\n",
    "RESNET50 MODEL - COMPREHENSIVE VALIDATION REPORT\n",
    "============================================================\n",
    "Generated: {datetime.datetime.now()}\n",
    "\n",
    "DATASET INFORMATION:\n",
    "- Training samples: {val_generator.samples}\n",
    "- Number of classes: {self.num_classes}\n",
    "- Class names: {list(class_indices.keys())}\n",
    "\n",
    "OVERALL METRICS:\n",
    "----------------------------------------\n",
    "Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\n",
    "Precision: {precision:.4f} ({precision*100:.2f}%)\n",
    "Recall:    {recall:.4f} ({recall*100:.2f}%)\n",
    "F1-Score:  {f1:.4f} ({f1*100:.2f}%)\n",
    "\n",
    "CONFUSION MATRIX SUMMARY:\n",
    "----------------------------------------\n",
    "Total True Positives (TP):  {int(np.sum(TP))}\n",
    "Total True Negatives (TN):  {int(np.sum(TN))}\n",
    "Total False Positives (FP): {int(np.sum(FP))}\n",
    "Total False Negatives (FN): {int(np.sum(FN))}\n",
    "\n",
    "DETAILED PER-CLASS METRICS:\n",
    "----------------------------------------\n",
    "{'Class':<20} {'TP':<8} {'TN':<8} {'FP':<8} {'FN':<8} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\n",
    "{'-'*90}\n",
    "\"\"\"\n",
    "        # Add per-class metrics\n",
    "        class_names = list(class_indices.keys())\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            class_precision = TP[i] / (TP[i] + FP[i]) if (TP[i] + FP[i]) > 0 else 0\n",
    "            class_recall = TP[i] / (TP[i] + FN[i]) if (TP[i] + FN[i]) > 0 else 0\n",
    "            class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0\n",
    "            \n",
    "            report_content += f\"{class_name:<20} {int(TP[i]):<8} {int(TN[i]):<8} {int(FP[i]):<8} {int(FN[i]):<8} {class_precision:.4f}     {class_recall:.4f}      {class_f1:.4f}\\n\"\n",
    "\n",
    "        # Performance assessment\n",
    "        report_content += f\"\"\"\n",
    "PERFORMANCE ASSESSMENT:\n",
    "----------------------------------------\n",
    "\"\"\"\n",
    "        if accuracy >= 0.90:\n",
    "            report_content += \"90%+ Accuracy Achieved!\"\n",
    "        elif accuracy >= 0.85:\n",
    "            report_content += \"85%+ Accuracy!\"\n",
    "        elif accuracy >= 0.80:\n",
    "            report_content += \"80%+ Accuracy!\"\n",
    "        elif accuracy >= 0.70:\n",
    "            report_content += \"70%+ Accuracy\"\n",
    "        else:\n",
    "            report_content += \"NEEDS IMPROVEMENT\"\n",
    "\n",
    "        report_content += f\"\"\"\n",
    "\n",
    "MODEL TRAINING INFORMATION:\n",
    "----------------------------------------\n",
    "- Pre-trained model: ResNet50 with ImageNet weights\n",
    "- Total epochs: {self.epochs}\n",
    "- Batch size: {self.batch_size}\n",
    "- Image size: {self.img_size}\n",
    "- Number of classes: {self.num_classes}\n",
    "- Model saved: {self.model_path}\n",
    "\"\"\"\n",
    "\n",
    "        # Save report\n",
    "        with open(self.report_path, 'w') as f:\n",
    "            f.write(report_content)\n",
    "\n",
    "        print(f\"Report saved to: {self.report_path}\")\n",
    "        return report_content\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main execution function\"\"\"\n",
    "        print(\"STARTING RESNET50 FOOD CLASSIFICATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load data\n",
    "        train_gen, val_gen, class_indices = self.load_data()\n",
    "        \n",
    "        # Train model\n",
    "        model, history = self.train_model(train_gen, val_gen)\n",
    "        print(\"Training completed!\")\n",
    "        \n",
    "        # Generate report\n",
    "        report_content = self.generate_report(model, val_gen, class_indices)\n",
    "        \n",
    "        # Final results summary\n",
    "        print(f\"\\n📊 FINAL RESULTS SUMMARY:\")\n",
    "        print(f\"   Accuracy:  {history.history['val_accuracy'][-1]:.4f} ({history.history['val_accuracy'][-1]*100:.2f}%)\")\n",
    "        print(f\"   Precision: {history.history['val_precision'][-1]:.4f} ({history.history['val_precision'][-1]*100:.2f}%)\")\n",
    "        print(f\"   Recall:    {history.history['val_recall'][-1]:.4f} ({history.history['val_recall'][-1]*100:.2f}%)\")\n",
    "        print(f\"   Model saved: {self.model_path}\")\n",
    "        print(f\"   Report saved: {self.report_path}\")\n",
    "        \n",
    "        return model, report_content\n",
    "\n",
    "# Run ResNet Model\n",
    "print(\"Starting ResNet Model...\")\n",
    "resnet_classifier = ResNetFoodClassifier()\n",
    "resnet_model, resnet_report = resnet_classifier.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Augmentation process for 34 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU and setup\n",
    "!nvidia-smi\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Configure GPU for better performance\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✓ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "\n",
    "# **Configuration and Imports**\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import random\n",
    "import uuid\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"All imports completed successfully!\")\n",
    "\n",
    "# **Configuration Class**\n",
    "class DataAugmentationConfig:\n",
    "    \"\"\"Configuration for data augmentation and file paths\"\"\"\n",
    "    def __init__(self):\n",
    "        # Kaggle dataset path (READ-ONLY)\n",
    "        self.INPUT_DATA_DIR = '/kaggle/input/food-classification-34-classes/food34_200_per_class'\n",
    "        # Working directory path (WRITABLE)\n",
    "        self.WORKING_DATA_DIR = '/kaggle/working/food34_200_per_class'\n",
    "        self.OUTPUT_DIR = '/kaggle/working'\n",
    "        \n",
    "        self.IMG_SIZE = (224, 224)\n",
    "        self.TARGET_IMAGES_PER_CLASS = 200\n",
    "        \n",
    "        # Save paths\n",
    "        self.AUGMENTATION_PICKLE_PATH = '/kaggle/working/data_augmentation.pkl'\n",
    "        \n",
    "        # Data augmentation parameters\n",
    "        self.ROTATION_RANGE = 25\n",
    "        self.WIDTH_SHIFT_RANGE = 0.15\n",
    "        self.HEIGHT_SHIFT_RANGE = 0.15\n",
    "        self.SHEAR_RANGE = 0.15\n",
    "        self.ZOOM_RANGE = 0.15\n",
    "        self.HORIZONTAL_FLIP = True\n",
    "        self.BRIGHTNESS_RANGE = [0.8, 1.2]\n",
    "        self.FILL_MODE = 'nearest'\n",
    "\n",
    "# **Setup Logging**\n",
    "def setup_augmentation_logging():\n",
    "    \"\"\"Setup logging for data augmentation process\"\"\"\n",
    "    try:\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # Clear existing handlers\n",
    "        for handler in logger.handlers[:]:\n",
    "            logger.removeHandler(handler)\n",
    "            \n",
    "        # Formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "        # File handler\n",
    "        file_handler = logging.FileHandler('/kaggle/working/data_augmentation.log', mode='w')\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "        \n",
    "        # Stream handler\n",
    "        stream_handler = logging.StreamHandler(sys.stdout)\n",
    "        stream_handler.setLevel(logging.INFO)\n",
    "        stream_handler.setFormatter(formatter)\n",
    "        \n",
    "        # Add handlers\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(stream_handler)\n",
    "        \n",
    "        logging.info(\"Data Augmentation Logging setup successfully for Kaggle!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Logging setup failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# **Data Copy Class**\n",
    "class DataCopier:\n",
    "    \"\"\"Copies data from read-only input to writable working directory\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        logging.info(\"DataCopier initialized\")\n",
    "    \n",
    "    def copy_dataset_to_working(self):\n",
    "        \"\"\"Copy entire dataset to working directory\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.config.WORKING_DATA_DIR):\n",
    "                logging.info(\"Working dataset already exists, skipping copy\")\n",
    "                return True\n",
    "                \n",
    "            logging.info(\"Copying dataset from input to working directory...\")\n",
    "            shutil.copytree(self.config.INPUT_DATA_DIR, self.config.WORKING_DATA_DIR)\n",
    "            logging.info(\"✓ Dataset copied successfully to working directory\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error copying dataset: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# **Data Analysis Class**\n",
    "class DataAnalyzer:\n",
    "    \"\"\"Analyzes dataset and identifies classes needing augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.train_counts = {}\n",
    "        self.val_counts = {}\n",
    "        self.test_counts = {}\n",
    "        logging.info(\"DataAnalyzer initialized\")\n",
    "    \n",
    "    def count_images_in_folder(self, folder_path):\n",
    "        \"\"\"Count images in a specific folder\"\"\"\n",
    "        counts = {}\n",
    "        if not os.path.exists(folder_path):\n",
    "            return counts\n",
    "            \n",
    "        for class_name in sorted(os.listdir(folder_path)):\n",
    "            class_path = os.path.join(folder_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                image_count = sum(1 for f in os.listdir(class_path) \n",
    "                                if f.lower().endswith(('.jpg','.jpeg','.png','.bmp','.gif','.tif','.tiff')))\n",
    "                counts[class_name] = image_count\n",
    "        return counts\n",
    "    \n",
    "    def analyze_dataset(self):\n",
    "        \"\"\"Analyze complete dataset structure\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Analyzing dataset structure...\")\n",
    "            \n",
    "            # Count images in each split (using WORKING directory)\n",
    "            train_dir = os.path.join(self.config.WORKING_DATA_DIR, 'train')\n",
    "            val_dir = os.path.join(self.config.WORKING_DATA_DIR, 'val')\n",
    "            test_dir = os.path.join(self.config.WORKING_DATA_DIR, 'test')\n",
    "            \n",
    "            self.train_counts = self.count_images_in_folder(train_dir)\n",
    "            self.val_counts = self.count_images_in_folder(val_dir)\n",
    "            self.test_counts = self.count_images_in_folder(test_dir)\n",
    "            \n",
    "            # Log results\n",
    "            logging.info(\"=== DATASET ANALYSIS RESULTS ===\")\n",
    "            logging.info(f\"Total classes found: {len(self.train_counts)}\")\n",
    "            \n",
    "            logging.info(\"\\nTRAINING SET (class: count):\")\n",
    "            for class_name, count in self.train_counts.items():\n",
    "                logging.info(f\"  {class_name}: {count} images\")\n",
    "            \n",
    "            # Identify classes needing augmentation\n",
    "            classes_needing_augmentation = [\n",
    "                class_name for class_name, count in self.train_counts.items() \n",
    "                if count < self.config.TARGET_IMAGES_PER_CLASS\n",
    "            ]\n",
    "            \n",
    "            logging.info(f\"\\nClasses needing augmentation: {len(classes_needing_augmentation)}\")\n",
    "            for class_name in classes_needing_augmentation:\n",
    "                current_count = self.train_counts[class_name]\n",
    "                needed = self.config.TARGET_IMAGES_PER_CLASS - current_count\n",
    "                logging.info(f\"  {class_name}: {current_count} -> needs {needed} more images\")\n",
    "            \n",
    "            return classes_needing_augmentation\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error analyzing dataset: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# **Data Augmentation Class**\n",
    "class DataAugmentor:\n",
    "    \"\"\"Handles data augmentation for classes with insufficient images\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.augmentation_results = {}\n",
    "        logging.info(\"DataAugmentor initialized\")\n",
    "    \n",
    "    def setup_augmentation_generator(self):\n",
    "        \"\"\"Setup ImageDataGenerator for augmentation\"\"\"\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=self.config.ROTATION_RANGE,\n",
    "            width_shift_range=self.config.WIDTH_SHIFT_RANGE,\n",
    "            height_shift_range=self.config.HEIGHT_SHIFT_RANGE,\n",
    "            shear_range=self.config.SHEAR_RANGE,\n",
    "            zoom_range=self.config.ZOOM_RANGE,\n",
    "            horizontal_flip=self.config.HORIZONTAL_FLIP,\n",
    "            brightness_range=self.config.BRIGHTNESS_RANGE,\n",
    "            fill_mode=self.config.FILL_MODE\n",
    "        )\n",
    "    \n",
    "    def augment_class(self, class_folder, needed_count):\n",
    "        \"\"\"Augment images for a specific class\"\"\"\n",
    "        try:\n",
    "            # Get all image files in class folder\n",
    "            image_files = [\n",
    "                f for f in os.listdir(class_folder) \n",
    "                if f.lower().endswith(('.jpg','.jpeg','.png','.bmp','.gif','.tif','.tiff'))\n",
    "            ]\n",
    "            \n",
    "            if not image_files:\n",
    "                logging.warning(f\"No source images found in {class_folder}\")\n",
    "                return 0\n",
    "            \n",
    "            datagen = self.setup_augmentation_generator()\n",
    "            created_count = 0\n",
    "            attempts = 0\n",
    "            max_attempts = needed_count * 15  # Safety limit\n",
    "            \n",
    "            logging.info(f\"Augmenting {class_folder}: need {needed_count} new images\")\n",
    "            \n",
    "            while created_count < needed_count and attempts < max_attempts:\n",
    "                attempts += 1\n",
    "                \n",
    "                # Randomly select source image\n",
    "                source_filename = random.choice(image_files)\n",
    "                source_path = os.path.join(class_folder, source_filename)\n",
    "                \n",
    "                try:\n",
    "                    # Load and preprocess image\n",
    "                    img = Image.open(source_path).convert('RGB')\n",
    "                    img = img.resize(self.config.IMG_SIZE)\n",
    "                    img_array = np.array(img)\n",
    "                    \n",
    "                    # Expand dimensions for generator\n",
    "                    img_batch = np.expand_dims(img_array, axis=0)\n",
    "                    \n",
    "                    # Generate augmented image\n",
    "                    aug_iterator = datagen.flow(img_batch, batch_size=1)\n",
    "                    augmented_array = next(aug_iterator)[0].astype('uint8')\n",
    "                    \n",
    "                    # Convert back to PIL Image and save\n",
    "                    augmented_img = Image.fromarray(augmented_array)\n",
    "                    new_filename = f\"aug_{uuid.uuid4().hex}.jpg\"\n",
    "                    new_filepath = os.path.join(class_folder, new_filename)\n",
    "                    \n",
    "                    augmented_img.save(new_filepath, quality=95, optimize=True)\n",
    "                    created_count += 1\n",
    "                    \n",
    "                    if created_count % 20 == 0:  # Progress update\n",
    "                        logging.info(f\"  Created {created_count}/{needed_count} for {os.path.basename(class_folder)}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Failed to augment {source_path}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            logging.info(f\"Completed {class_folder}: created {created_count} new images\")\n",
    "            return created_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error augmenting class {class_folder}: {str(e)}\")\n",
    "            return 0\n",
    "    \n",
    "    def perform_augmentation(self, classes_to_augment, analyzer):\n",
    "        \"\"\"Perform augmentation for all specified classes\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting data augmentation process...\")\n",
    "            \n",
    "            train_dir = os.path.join(self.config.WORKING_DATA_DIR, 'train')\n",
    "            augmentation_summary = {}\n",
    "            \n",
    "            for class_name in classes_to_augment:\n",
    "                class_folder = os.path.join(train_dir, class_name)\n",
    "                \n",
    "                if not os.path.exists(class_folder):\n",
    "                    logging.warning(f\"Class folder not found: {class_folder}\")\n",
    "                    continue\n",
    "                \n",
    "                current_count = analyzer.train_counts[class_name]\n",
    "                needed_count = self.config.TARGET_IMAGES_PER_CLASS - current_count\n",
    "                \n",
    "                if needed_count <= 0:\n",
    "                    logging.info(f\"{class_name} already has sufficient images ({current_count})\")\n",
    "                    continue\n",
    "                \n",
    "                # Perform augmentation\n",
    "                created_count = self.augment_class(class_folder, needed_count)\n",
    "                \n",
    "                # Record results\n",
    "                augmentation_summary[class_name] = {\n",
    "                    'before': current_count,\n",
    "                    'created': created_count,\n",
    "                    'after': current_count + created_count,\n",
    "                    'success': created_count >= needed_count * 0.8  # 80% success threshold\n",
    "                }\n",
    "            \n",
    "            self.augmentation_results = augmentation_summary\n",
    "            self._save_augmentation_report()\n",
    "            return augmentation_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in augmentation process: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _save_augmentation_report(self):\n",
    "        \"\"\"Save augmentation results to pickle file\"\"\"\n",
    "        try:\n",
    "            # Prepare data for pickle\n",
    "            augmentation_data = {\n",
    "                'config': {\n",
    "                    'target_images_per_class': self.config.TARGET_IMAGES_PER_CLASS,\n",
    "                    'augmentation_parameters': {\n",
    "                        'rotation_range': self.config.ROTATION_RANGE,\n",
    "                        'width_shift_range': self.config.WIDTH_SHIFT_RANGE,\n",
    "                        'height_shift_range': self.config.HEIGHT_SHIFT_RANGE,\n",
    "                        'shear_range': self.config.SHEAR_RANGE,\n",
    "                        'zoom_range': self.config.ZOOM_RANGE,\n",
    "                        'horizontal_flip': self.config.HORIZONTAL_FLIP,\n",
    "                        'brightness_range': self.config.BRIGHTNESS_RANGE\n",
    "                    }\n",
    "                },\n",
    "                'results': self.augmentation_results,\n",
    "                'timestamp': str(np.datetime64('now'))\n",
    "            }\n",
    "            \n",
    "            # Save to pickle\n",
    "            with open(self.config.AUGMENTATION_PICKLE_PATH, 'wb') as f:\n",
    "                pickle.dump(augmentation_data, f)\n",
    "            \n",
    "            logging.info(f\"Augmentation report saved to: {self.config.AUGMENTATION_PICKLE_PATH}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving augmentation report: {str(e)}\")\n",
    "\n",
    "# **Verification Class**\n",
    "class DataVerifier:\n",
    "    \"\"\"Verifies all created files and data integrity\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        logging.info(\"DataVerifier initialized\")\n",
    "    \n",
    "    def verify_augmentation(self):\n",
    "        \"\"\"Verify augmentation results\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting augmentation verification...\")\n",
    "            \n",
    "            verification_results = {\n",
    "                'augmentation_pickle': self._verify_augmentation_pickle(),\n",
    "                'image_counts': self._verify_image_counts()\n",
    "            }\n",
    "            \n",
    "            self._log_verification_results(verification_results)\n",
    "            return verification_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Verification failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _verify_augmentation_pickle(self):\n",
    "        \"\"\"Verify augmentation pickle file\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.config.AUGMENTATION_PICKLE_PATH):\n",
    "                return False, \"Augmentation pickle file not found\"\n",
    "            \n",
    "            with open(self.config.AUGMENTATION_PICKLE_PATH, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            required_keys = ['config', 'results', 'timestamp']\n",
    "            if all(key in data for key in required_keys):\n",
    "                return True, f\"Augmentation pickle verified: {len(data['results'])} classes\"\n",
    "            else:\n",
    "                return False, \"Augmentation pickle missing required keys\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, f\"Error loading augmentation pickle: {str(e)}\"\n",
    "    \n",
    "    def _verify_image_counts(self):\n",
    "        \"\"\"Verify image counts after augmentation\"\"\"\n",
    "        try:\n",
    "            train_dir = os.path.join(self.config.WORKING_DATA_DIR, 'train')\n",
    "            classes_with_insufficient = []\n",
    "            \n",
    "            for class_name in os.listdir(train_dir):\n",
    "                class_path = os.path.join(train_dir, class_name)\n",
    "                if os.path.isdir(class_path):\n",
    "                    image_count = len([f for f in os.listdir(class_path) \n",
    "                                     if f.lower().endswith(('.jpg','.jpeg','.png'))])\n",
    "                    if image_count < self.config.TARGET_IMAGES_PER_CLASS:\n",
    "                        classes_with_insufficient.append((class_name, image_count))\n",
    "            \n",
    "            if not classes_with_insufficient:\n",
    "                return True, f\"All classes have at least {self.config.TARGET_IMAGES_PER_CLASS} images\"\n",
    "            else:\n",
    "                return False, f\"Classes with insufficient images: {classes_with_insufficient}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, f\"Error verifying image counts: {str(e)}\"\n",
    "    \n",
    "    def _log_verification_results(self, results):\n",
    "        \"\"\"Log verification results\"\"\"\n",
    "        logging.info(\"=== AUGMENTATION VERIFICATION RESULTS ===\")\n",
    "        for check_name, (status, message) in results.items():\n",
    "            status_symbol = \"✓\" if status else \"✗\"\n",
    "            logging.info(f\"{status_symbol} {check_name}: {message}\")\n",
    "\n",
    "# **Main Pipeline Class**\n",
    "class DataAugmentationPipeline:\n",
    "    \"\"\"Main pipeline for data augmentation only\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.config = DataAugmentationConfig()\n",
    "        self.copier = None\n",
    "        self.analyzer = None\n",
    "        self.augmentor = None\n",
    "        self.verifier = None\n",
    "        logging.info(\"DataAugmentationPipeline initialized\")\n",
    "    \n",
    "    def run_augmentation_pipeline(self):\n",
    "        \"\"\"Run the data augmentation pipeline\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting Data Augmentation Pipeline on Kaggle...\")\n",
    "            \n",
    "            # Step 1: Copy data to working directory\n",
    "            self.copier = DataCopier(self.config)\n",
    "            self.copier.copy_dataset_to_working()\n",
    "            \n",
    "            # Step 2: Analyze dataset\n",
    "            self.analyzer = DataAnalyzer(self.config)\n",
    "            classes_needing_augmentation = self.analyzer.analyze_dataset()\n",
    "            \n",
    "            # Step 3: Perform data augmentation\n",
    "            self.augmentor = DataAugmentor(self.config)\n",
    "            augmentation_results = self.augmentor.perform_augmentation(\n",
    "                classes_needing_augmentation, self.analyzer\n",
    "            )\n",
    "            \n",
    "            # Step 4: Verify augmentation\n",
    "            self.verifier = DataVerifier(self.config)\n",
    "            verification_results = self.verifier.verify_augmentation()\n",
    "            \n",
    "            # Final report\n",
    "            self._generate_final_report(augmentation_results, verification_results)\n",
    "            \n",
    "            logging.info(\"Data Augmentation Pipeline completed successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Augmentation pipeline failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_final_report(self, augmentation_results, verification_results):\n",
    "        \"\"\"Generate final summary report\"\"\"\n",
    "        logging.info(\"\\n\" + \"=\"*80)\n",
    "        logging.info(\"DATA AUGMENTATION PIPELINE - FINAL REPORT\")\n",
    "        logging.info(\"=\"*80)\n",
    "        \n",
    "        # Augmentation summary\n",
    "        if augmentation_results:\n",
    "            total_created = sum(result['created'] for result in augmentation_results.values())\n",
    "            successful_augmentations = sum(1 for result in augmentation_results.values() if result['success'])\n",
    "            \n",
    "            logging.info(f\"AUGMENTATION SUMMARY:\")\n",
    "            logging.info(f\"  Classes augmented: {len(augmentation_results)}\")\n",
    "            logging.info(f\"  Total images created: {total_created}\")\n",
    "            logging.info(f\"  Successful augmentations: {successful_augmentations}/{len(augmentation_results)}\")\n",
    "        \n",
    "        # Verification summary\n",
    "        all_checks_passed = all(status for status, _ in verification_results.values())\n",
    "        \n",
    "        logging.info(f\"VERIFICATION SUMMARY:\")\n",
    "        for check_name, (status, message) in verification_results.items():\n",
    "            status_text = \"PASS\" if status else \"FAIL\"\n",
    "            logging.info(f\"  {check_name}: {status_text} - {message}\")\n",
    "        \n",
    "        logging.info(f\"OVERALL STATUS: {'COMPLETED SUCCESSFULLY' if all_checks_passed else 'COMPLETED WITH ISSUES'}\")\n",
    "        logging.info(\"=\"*80)\n",
    "\n",
    "# **Execute the augmentation pipeline**\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Setup logging\n",
    "        if setup_augmentation_logging():\n",
    "            # Run the augmentation pipeline\n",
    "            pipeline = DataAugmentationPipeline()\n",
    "            success = pipeline.run_augmentation_pipeline()\n",
    "            \n",
    "            if success:\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"🎉 DATA AUGMENTATION COMPLETED SUCCESSFULLY!\")\n",
    "                print(\"=\"*60)\n",
    "                print(\"Created files in /kaggle/working/:\")\n",
    "                print(\"  ✓ food34_200_per_class/ - Augmented dataset\")\n",
    "                print(\"  ✓ data_augmentation.pkl - Augmentation report\")\n",
    "                print(\"  ✓ data_augmentation.log - Detailed process log\")\n",
    "                print(\"\\nDataset is ready for model training!\")\n",
    "            else:\n",
    "                print(\"❌ Data augmentation failed. Check logs for details.\")\n",
    "        else:\n",
    "            print(\"Failed to setup logging.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Augmentation execution failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# **Quick verification function**\n",
    "def quick_augmentation_verification():\n",
    "    \"\"\"Quick verification of augmentation results\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"AUGMENTATION VERIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    config = DataAugmentationConfig()\n",
    "    \n",
    "    # Check augmentation pickle\n",
    "    aug_exists = os.path.exists(config.AUGMENTATION_PICKLE_PATH)\n",
    "    print(f\"Augmentation pickle: {'✓ EXISTS' if aug_exists else '✗ MISSING'}\")\n",
    "    \n",
    "    # Check working dataset\n",
    "    working_exists = os.path.exists(config.WORKING_DATA_DIR)\n",
    "    print(f\"Working dataset: {'✓ EXISTS' if working_exists else '✗ MISSING'}\")\n",
    "    \n",
    "    # Check log file\n",
    "    log_exists = os.path.exists('/kaggle/working/data_augmentation.log')\n",
    "    print(f\"Log file: {'✓ EXISTS' if log_exists else '✗ MISSING'}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run quick verification\n",
    "quick_augmentation_verification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **JSON Files Creation Code for 34 Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Files Creation Code\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# **Configuration Class**\n",
    "class JSONConfig:\n",
    "    \"\"\"Configuration for JSON file creation\"\"\"\n",
    "    def __init__(self):\n",
    "        self.OUTPUT_DIR = '/kaggle/working'\n",
    "        self.JSON_PICKLE_PATH = '/kaggle/working/json_all_food_classes.pkl'\n",
    "        self.JSON_FOLDER_PATH = '/kaggle/working/json_folder'\n",
    "\n",
    "# **Setup Logging**\n",
    "def setup_json_logging():\n",
    "    \"\"\"Setup logging for JSON creation process\"\"\"\n",
    "    try:\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # Clear existing handlers\n",
    "        for handler in logger.handlers[:]:\n",
    "            logger.removeHandler(handler)\n",
    "            \n",
    "        # Formatter\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        \n",
    "        # File handler\n",
    "        file_handler = logging.FileHandler('/kaggle/working/json_creation.log', mode='w')\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "        \n",
    "        # Stream handler\n",
    "        stream_handler = logging.StreamHandler(sys.stdout)\n",
    "        stream_handler.setLevel(logging.INFO)\n",
    "        stream_handler.setFormatter(formatter)\n",
    "        \n",
    "        # Add handlers\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(stream_handler)\n",
    "        \n",
    "        logging.info(\"JSON Creation Logging setup successfully for Kaggle!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"JSON Logging setup failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# **JSON File Creator Class**\n",
    "class JSONCreator:\n",
    "    \"\"\"Creates JSON files for all 34 food classes\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.classes_data = []\n",
    "        logging.info(\"JSONCreator initialized\")\n",
    "    \n",
    "    def create_classes_data(self):\n",
    "        \"\"\"Create the complete classes data structure\"\"\"\n",
    "        self.classes_data = [\n",
    "            {\"class_name\":\"Baked_potato\",\"label_index\":0,\"nutrition\":{\"protein\":7,\"fiber\":5,\"calories\":260,\"carbohydrates\":60,\"fat\":1}},\n",
    "            {\"class_name\":\"Crispy_chicken\",\"label_index\":1,\"nutrition\":{\"protein\":28,\"fiber\":1,\"calories\":420,\"carbohydrates\":20,\"fat\":24}},\n",
    "            {\"class_name\":\"Donut\",\"label_index\":2,\"nutrition\":{\"protein\":4,\"fiber\":1,\"calories\":260,\"carbohydrates\":30,\"fat\":14}},\n",
    "            {\"class_name\":\"Fries\",\"label_index\":3,\"nutrition\":{\"protein\":4,\"fiber\":3,\"calories\":312,\"carbohydrates\":41,\"fat\":15}},\n",
    "            {\"class_name\":\"Hot_Dog\",\"label_index\":4,\"nutrition\":{\"protein\":10,\"fiber\":1,\"calories\":290,\"carbohydrates\":20,\"fat\":20}},\n",
    "            {\"class_name\":\"Sandwich\",\"label_index\":5,\"nutrition\":{\"protein\":18,\"fiber\":3,\"calories\":350,\"carbohydrates\":35,\"fat\":12}},\n",
    "            {\"class_name\":\"Taco\",\"label_index\":6,\"nutrition\":{\"protein\":12,\"fiber\":3,\"calories\":170,\"carbohydrates\":15,\"fat\":8}},\n",
    "            {\"class_name\":\"Taquito\",\"label_index\":7,\"nutrition\":{\"protein\":10,\"fiber\":2,\"calories\":220,\"carbohydrates\":18,\"fat\":11}},\n",
    "            {\"class_name\":\"apple_pie\",\"label_index\":8,\"nutrition\":{\"protein\":2,\"fiber\":2,\"calories\":320,\"carbohydrates\":45,\"fat\":15}},\n",
    "            {\"class_name\":\"burger\",\"label_index\":9,\"nutrition\":{\"protein\":25,\"fiber\":2,\"calories\":500,\"carbohydrates\":40,\"fat\":27}},\n",
    "            {\"class_name\":\"butter_naan\",\"label_index\":10,\"nutrition\":{\"protein\":8,\"fiber\":2,\"calories\":300,\"carbohydrates\":45,\"fat\":11}},\n",
    "            {\"class_name\":\"chai\",\"label_index\":11,\"nutrition\":{\"protein\":2,\"fiber\":0,\"calories\":120,\"carbohydrates\":15,\"fat\":5}},\n",
    "            {\"class_name\":\"chapati\",\"label_index\":12,\"nutrition\":{\"protein\":6,\"fiber\":3,\"calories\":120,\"carbohydrates\":20,\"fat\":3}},\n",
    "            {\"class_name\":\"cheesecake\",\"label_index\":13,\"nutrition\":{\"protein\":6,\"fiber\":0,\"calories\":350,\"carbohydrates\":25,\"fat\":26}},\n",
    "            {\"class_name\":\"chicken_curry\",\"label_index\":14,\"nutrition\":{\"protein\":22,\"fiber\":2,\"calories\":320,\"carbohydrates\":8,\"fat\":20}},\n",
    "            {\"class_name\":\"chole_bhature\",\"label_index\":15,\"nutrition\":{\"protein\":15,\"fiber\":8,\"calories\":650,\"carbohydrates\":80,\"fat\":30}},\n",
    "            {\"class_name\":\"dal_makhani\",\"label_index\":16,\"nutrition\":{\"protein\":12,\"fiber\":6,\"calories\":280,\"carbohydrates\":30,\"fat\":12}},\n",
    "            {\"class_name\":\"dhokla\",\"label_index\":17,\"nutrition\":{\"protein\":6,\"fiber\":2,\"calories\":120,\"carbohydrates\":18,\"fat\":4}},\n",
    "            {\"class_name\":\"fried_rice\",\"label_index\":18,\"nutrition\":{\"protein\":8,\"fiber\":2,\"calories\":350,\"carbohydrates\":55,\"fat\":12}},\n",
    "            {\"class_name\":\"ice_cream\",\"label_index\":19,\"nutrition\":{\"protein\":4,\"fiber\":0,\"calories\":207,\"carbohydrates\":24,\"fat\":11}},\n",
    "            {\"class_name\":\"idli\",\"label_index\":20,\"nutrition\":{\"protein\":6,\"fiber\":1,\"calories\":130,\"carbohydrates\":25,\"fat\":1}},\n",
    "            {\"class_name\":\"jalebi\",\"label_index\":21,\"nutrition\":{\"protein\":1,\"fiber\":0,\"calories\":300,\"carbohydrates\":50,\"fat\":12}},\n",
    "            {\"class_name\":\"kadai_paneer\",\"label_index\":22,\"nutrition\":{\"protein\":18,\"fiber\":3,\"calories\":420,\"carbohydrates\":12,\"fat\":30}},\n",
    "            {\"class_name\":\"kathi_rolls\",\"label_index\":23,\"nutrition\":{\"protein\":20,\"fiber\":3,\"calories\":420,\"carbohydrates\":40,\"fat\":18}},\n",
    "            {\"class_name\":\"kulfi\",\"label_index\":24,\"nutrition\":{\"protein\":6,\"fiber\":0,\"calories\":230,\"carbohydrates\":25,\"fat\":12}},\n",
    "            {\"class_name\":\"masala_dosa\",\"label_index\":25,\"nutrition\":{\"protein\":6,\"fiber\":3,\"calories\":200,\"carbohydrates\":30,\"fat\":6}},\n",
    "            {\"class_name\":\"momos\",\"label_index\":26,\"nutrition\":{\"protein\":10,\"fiber\":2,\"calories\":220,\"carbohydrates\":28,\"fat\":8}},\n",
    "            {\"class_name\":\"omlette\",\"label_index\":27,\"nutrition\":{\"protein\":12,\"fiber\":0,\"calories\":154,\"carbohydrates\":1,\"fat\":11}},\n",
    "            {\"class_name\":\"paani_puri\",\"label_index\":28,\"nutrition\":{\"protein\":4,\"fiber\":2,\"calories\":80,\"carbohydrates\":12,\"fat\":3}},\n",
    "            {\"class_name\":\"pakode\",\"label_index\":29,\"nutrition\":{\"protein\":6,\"fiber\":2,\"calories\":280,\"carbohydrates\":20,\"fat\":18}},\n",
    "            {\"class_name\":\"pav_bhaji\",\"label_index\":30,\"nutrition\":{\"protein\":9,\"fiber\":5,\"calories\":350,\"carbohydrates\":50,\"fat\":10}},\n",
    "            {\"class_name\":\"pizza\",\"label_index\":31,\"nutrition\":{\"protein\":12,\"fiber\":2,\"calories\":285,\"carbohydrates\":36,\"fat\":10}},\n",
    "            {\"class_name\":\"samosa\",\"label_index\":32,\"nutrition\":{\"protein\":5,\"fiber\":2,\"calories\":260,\"carbohydrates\":30,\"fat\":14}},\n",
    "            {\"class_name\":\"sushi\",\"label_index\":33,\"nutrition\":{\"protein\":9,\"fiber\":1,\"calories\":200,\"carbohydrates\":28,\"fat\":6}}\n",
    "        ]\n",
    "        \n",
    "        logging.info(f\"Created data for {len(self.classes_data)} classes\")\n",
    "        return self.classes_data\n",
    "    \n",
    "    def create_individual_json_files(self):\n",
    "        \"\"\"Create individual JSON files for each class\"\"\"\n",
    "        try:\n",
    "            # Create JSON folder\n",
    "            os.makedirs(self.config.JSON_FOLDER_PATH, exist_ok=True)\n",
    "            \n",
    "            logging.info(\"Creating individual JSON files...\")\n",
    "            \n",
    "            for class_data in self.classes_data:\n",
    "                filename = f\"{class_data['class_name']}.json\"\n",
    "                filepath = os.path.join(self.config.JSON_FOLDER_PATH, filename)\n",
    "                \n",
    "                with open(filepath, 'w') as f:\n",
    "                    json.dump(class_data, f, indent=2)\n",
    "                \n",
    "                logging.info(f\"Created: {filepath}\")\n",
    "            \n",
    "            logging.info(f\"All {len(self.classes_data)} JSON files created successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating JSON files: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def create_combined_pickle(self):\n",
    "        \"\"\"Create combined pickle file with all classes data\"\"\"\n",
    "        try:\n",
    "            with open(self.config.JSON_PICKLE_PATH, 'wb') as f:\n",
    "                pickle.dump(self.classes_data, f)\n",
    "            \n",
    "            logging.info(f\"Combined pickle file saved: {self.config.JSON_PICKLE_PATH}\")\n",
    "            \n",
    "            # Verify the pickle file\n",
    "            with open(self.config.JSON_PICKLE_PATH, 'rb') as f:\n",
    "                verified_data = pickle.load(f)\n",
    "            \n",
    "            logging.info(f\"Pickle verification successful: {len(verified_data)} classes loaded\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating combined pickle: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# **Verification Class**\n",
    "class JSONVerifier:\n",
    "    \"\"\"Verifies JSON files creation\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        logging.info(\"JSONVerifier initialized\")\n",
    "    \n",
    "    def verify_json_files(self):\n",
    "        \"\"\"Verify JSON files creation\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting JSON files verification...\")\n",
    "            \n",
    "            verification_results = {\n",
    "                'json_pickle': self._verify_json_pickle(),\n",
    "                'json_files': self._verify_json_files()\n",
    "            }\n",
    "            \n",
    "            self._log_verification_results(verification_results)\n",
    "            return verification_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"JSON verification failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _verify_json_pickle(self):\n",
    "        \"\"\"Verify JSON pickle file\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.config.JSON_PICKLE_PATH):\n",
    "                return False, \"JSON pickle file not found\"\n",
    "            \n",
    "            with open(self.config.JSON_PICKLE_PATH, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            if len(data) == 34 and all('class_name' in item for item in data):\n",
    "                return True, f\"JSON pickle verified: {len(data)} classes\"\n",
    "            else:\n",
    "                return False, f\"JSON pickle has incorrect format: {len(data)} classes\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, f\"Error loading JSON pickle: {str(e)}\"\n",
    "    \n",
    "    def _verify_json_files(self):\n",
    "        \"\"\"Verify individual JSON files\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.config.JSON_FOLDER_PATH):\n",
    "                return False, \"JSON folder not found\"\n",
    "            \n",
    "            json_files = [f for f in os.listdir(self.config.JSON_FOLDER_PATH) if f.endswith('.json')]\n",
    "            \n",
    "            if len(json_files) == 34:\n",
    "                return True, f\"All 34 JSON files created successfully\"\n",
    "            else:\n",
    "                return False, f\"Expected 34 JSON files, found {len(json_files)}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False, f\"Error verifying JSON files: {str(e)}\"\n",
    "    \n",
    "    def _log_verification_results(self, results):\n",
    "        \"\"\"Log verification results\"\"\"\n",
    "        logging.info(\"=== JSON FILES VERIFICATION RESULTS ===\")\n",
    "        for check_name, (status, message) in results.items():\n",
    "            status_symbol = \"✓\" if status else \"✗\"\n",
    "            logging.info(f\"{status_symbol} {check_name}: {message}\")\n",
    "\n",
    "# **Main JSON Creation Pipeline**\n",
    "class JSONCreationPipeline:\n",
    "    \"\"\"Main pipeline for JSON files creation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.config = JSONConfig()\n",
    "        self.json_creator = None\n",
    "        self.verifier = None\n",
    "        logging.info(\"JSONCreationPipeline initialized\")\n",
    "    \n",
    "    def run_json_creation_pipeline(self):\n",
    "        \"\"\"Run the JSON files creation pipeline\"\"\"\n",
    "        try:\n",
    "            logging.info(\"Starting JSON Files Creation Pipeline on Kaggle...\")\n",
    "            \n",
    "            # Step 1: Create JSON files\n",
    "            self.json_creator = JSONCreator(self.config)\n",
    "            self.json_creator.create_classes_data()\n",
    "            self.json_creator.create_individual_json_files()\n",
    "            self.json_creator.create_combined_pickle()\n",
    "            \n",
    "            # Step 2: Verify JSON files\n",
    "            self.verifier = JSONVerifier(self.config)\n",
    "            verification_results = self.verifier.verify_json_files()\n",
    "            \n",
    "            # Final report\n",
    "            self._generate_final_report(verification_results)\n",
    "            \n",
    "            logging.info(\"JSON Files Creation Pipeline completed successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"JSON creation pipeline failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_final_report(self, verification_results):\n",
    "        \"\"\"Generate final summary report\"\"\"\n",
    "        logging.info(\"\\n\" + \"=\"*80)\n",
    "        logging.info(\"JSON FILES CREATION - FINAL REPORT\")\n",
    "        logging.info(\"=\"*80)\n",
    "        \n",
    "        # Verification summary\n",
    "        all_checks_passed = all(status for status, _ in verification_results.values())\n",
    "        \n",
    "        logging.info(f\"CREATION SUMMARY:\")\n",
    "        for check_name, (status, message) in verification_results.items():\n",
    "            status_text = \"PASS\" if status else \"FAIL\"\n",
    "            logging.info(f\"  {check_name}: {status_text} - {message}\")\n",
    "        \n",
    "        logging.info(f\"OVERALL STATUS: {'COMPLETED SUCCESSFULLY' if all_checks_passed else 'COMPLETED WITH ISSUES'}\")\n",
    "        logging.info(\"=\"*80)\n",
    "\n",
    "# **Execute the JSON creation pipeline**\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Setup logging\n",
    "        if setup_json_logging():\n",
    "            # Run the JSON creation pipeline\n",
    "            pipeline = JSONCreationPipeline()\n",
    "            success = pipeline.run_json_creation_pipeline()\n",
    "            \n",
    "            if success:\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"🎉 JSON FILES CREATION COMPLETED SUCCESSFULLY!\")\n",
    "                print(\"=\"*60)\n",
    "                print(\"Created files in /kaggle/working/:\")\n",
    "                print(\"  ✓ json_all_food_classes.pkl - Combined class data\")\n",
    "                print(\"  ✓ json_folder/ - Individual JSON files for all 34 classes\")\n",
    "                print(\"  ✓ json_creation.log - Detailed process log\")\n",
    "                print(\"\\nJSON files are ready for use!\")\n",
    "            else:\n",
    "                print(\"❌ JSON files creation failed. Check logs for details.\")\n",
    "        else:\n",
    "            print(\"Failed to setup logging.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"JSON creation execution failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# **Quick verification function**\n",
    "def quick_json_verification():\n",
    "    \"\"\"Quick verification of JSON files\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"JSON FILES VERIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    config = JSONConfig()\n",
    "    \n",
    "    # Check JSON pickle\n",
    "    json_pickle_exists = os.path.exists(config.JSON_PICKLE_PATH)\n",
    "    print(f\"JSON pickle: {'✓ EXISTS' if json_pickle_exists else '✗ MISSING'}\")\n",
    "    \n",
    "    # Check JSON folder\n",
    "    json_folder_exists = os.path.exists(config.JSON_FOLDER_PATH)\n",
    "    if json_folder_exists:\n",
    "        json_files = len([f for f in os.listdir(config.JSON_FOLDER_PATH) if f.endswith('.json')])\n",
    "        print(f\"JSON files: ✓ {json_files}/34 created\")\n",
    "    else:\n",
    "        print(f\"JSON folder: ✗ MISSING\")\n",
    "    \n",
    "    # Check log file\n",
    "    log_exists = os.path.exists('/kaggle/working/json_creation.log')\n",
    "    print(f\"Log file: {'✓ EXISTS' if log_exists else '✗ MISSING'}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Run quick verification\n",
    "quick_json_verification()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8533940,
     "sourceId": 13444634,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
